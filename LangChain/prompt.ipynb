{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from api import API_KEYS\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEYS[\"OPENAI\"]\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = API_KEYS[\"HUGGINFACE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API CALLING TEST\n",
    "\n",
    "### 프롬포트 생성\n",
    "\n",
    "- PromptTemplate은 LLM에 문장을 전달하기 전에 문장 구성을 편리하게 만들어주는 역할\n",
    "- LLM이 어떤 문장을 만들어야 하는지를 알려주는 역할을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카메라를 홍보하기 위한 좋은 문구를 추천해줘?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"{product}를 홍보하기 위한 좋은 문구를 추천해줘?\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt.format(product=\"카메라\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "거북이입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm1 = ChatOpenAI(temperature=0,\n",
    "                  model_name='gpt-4')\n",
    "\n",
    "prompt = \"상범이는 거북이를 키우고 있습니다. 상범이가 키우고 있는 동물은?\"\n",
    "\n",
    "print(llm1.predict(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='거북이입니다.' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 42, 'total_tokens': 48}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-ea91daf9-1891-405f-8622-a39ab83a1a33-0' usage_metadata={'input_tokens': 42, 'output_tokens': 6, 'total_tokens': 48}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm1 = ChatOpenAI(temperature=0,\n",
    "                  model_name='gpt-4')\n",
    "\n",
    "prompt = \"상범이는 거북이를 키우고 있습니다. 상범이가 키우고 있는 동물은?\"\n",
    "\n",
    "print(llm1.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HUGGING FACE\n",
    "- 시간마다 request할 수 있는 양의 한계가 있음\n",
    "- google/flan-t5-xxl 모델 사용시, 바로 request 에러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm2 = HuggingFaceHub(repo_id = \"google/flan-t5-small\", \n",
    "                      model_kwargs={\"temperature\":0, \"max_depth\":512})\n",
    "\n",
    "completion = llm2(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "model_lab = ModelLaboratory.from_llms([llm1, llm2])\n",
    "model_lab.compare(\"대한민국의 가을은 몇 월부터 몇 월까지야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "                 max_tokens=2048,\n",
    "                 model_name='gpt-4',\n",
    "                 )\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"7개의 팀을 보여줘 {subject}.format\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두산 베어스', '롯데 자이언츠', '삼성 라이온즈', 'SK 와이번스', 'KIA 타이거즈', 'LG 트윈스', 'NC 다이노스']\n"
     ]
    }
   ],
   "source": [
    "query = \"한국의 야구팀은?\"\n",
    "\n",
    "output = llm.predict(text=prompt.format(subject=query))\n",
    "\n",
    "# 출력의 format 변경\n",
    "parsed_results = output_parser.parse(output)\n",
    "print(parsed_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1    The Fence \\n \\nTom Sawyer lived with his aunt because his mother and \\nfather were dead. Tom didn’t like going to school, and he didn’t like working. He liked playing and having adventures. One Friday, he didn’t go to school—he went to the river. \\nAunt Polly was angry. “You’re a bad boy!” she said. \\n“Tomorrow you can’t play with your friends because you didn’t go to school today. Tomorrow you’re going to work for me. You can paint the fence.” \\nSaturday morning, Tom was not happy, but he started to \\npaint the fence. His friend Jim was in the street. \\nTom asked him, “Do you want to paint?” \\nJim said, “No, I can’t. I’m going to get water.” \\nThen Ben came to Tom’s house. He watched Tom and \\nsaid, “I’m going to swim today. You can’t swim because you’re working.” \\nTom said, “This isn’t work. I like painting.” \\n“Can I paint, too?” Ben asked. \\n“No, you can’t,” Tom answered. “Aunt Polly asked me \\nbecause I’m a very good painter.” \\nBen said, “I’m a good painter, too. Please, can I paint? I \\nhave some fruit. Do you want it?” \\nOK,” Tom said. “Give me the fruit. Then you can paint.” \\nBen started to paint the fence. Later, many boys came to \\nTom’s house. They watched Ben, and they wanted to paint, too. \\nTom said, “Give me some food and you can paint.” \\n \\n1 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"The_Adventures_of_Tom_Sawyer.pdf\")\n",
    "document = loader.load()\n",
    "document[5].page_content[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(document, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마을 무덤에 있던 남자를 죽인 사람은 Injun Joe입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "                 model_name = 'gpt-3.5-turbo',\n",
    "                 )\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "query = \"마을 무덤에 있던 남자를 죽인 사람은 누구니?\"\n",
    "result = qa({'query': query})\n",
    "print(result['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
